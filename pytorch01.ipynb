{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import feature\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from skimage import img_as_float\n",
    "from skimage import io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from utils import mkdir, rmdir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 24\n",
    "CLASS_NUM = 43\n",
    "\n",
    "IMG_SIZE = (64, 64)\n",
    "\n",
    "MAX_ROTATION = 40\n",
    "\n",
    "MIN_BRIGHTNESS = 0.4\n",
    "MAX_BRIGHTNESS = 2.0\n",
    "\n",
    "MIN_CONTRAST = 0.4\n",
    "MAX_CONTRAST = 2.0\n",
    "\n",
    "MIN_SATURATION = 0.4\n",
    "MAX_SATURATION = 1.6\n",
    "\n",
    "DISTORTION = 0.4\n",
    "MAX_TRANSITION = 0.25\n",
    "\n",
    "MIN_SCALE = 0.7\n",
    "MAX_SCALE = 1.5\n",
    "\n",
    "NOISE_STD = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomNoise(tensor):\n",
    "    std = np.random.uniform(0, NOISE_STD)\n",
    "    return torch.clamp(tensor + torch.FloatTensor(tensor.size()).normal_(0, std), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = {\n",
    "    'default': T.Compose([\n",
    "        T.Resize(IMG_SIZE),\n",
    "        T.CenterCrop(IMG_SIZE),\n",
    "        T.ToTensor()\n",
    "    ]),\n",
    "    'train': T.Compose([\n",
    "        T.RandomAffine(MAX_ROTATION, (MAX_TRANSITION, MAX_TRANSITION), (MIN_SCALE, MAX_SCALE)),\n",
    "        T.RandomPerspective(DISTORTION),\n",
    "        T.Resize(IMG_SIZE),\n",
    "        T.CenterCrop(IMG_SIZE),\n",
    "        T.ToTensor(),\n",
    "        T.Lambda(RandomNoise),\n",
    "    ]),\n",
    "    'test': T.Compose([\n",
    "        T.Resize(IMG_SIZE),\n",
    "        T.CenterCrop(IMG_SIZE),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dataset/train.csv'\n",
    "test_path = 'dataset/test.csv'\n",
    "\n",
    "image_path = 'dataset/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, as_gray=True):\n",
    "    return Image.fromarray(255 - io.imread(path, as_gray=as_gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, path, image_path, \n",
    "                 target='classify',\n",
    "                 transform=my_transforms['default'],\n",
    "                 is_train=True, verbose=True):        \n",
    "        self.is_train = is_train\n",
    "        if not isinstance(transform, tuple):\n",
    "            self.transform = (transform, transform)\n",
    "        else:\n",
    "            self.transform = transform\n",
    "            \n",
    "        assert target in {'reconstruct', 'classify'}\n",
    "        self.target = target\n",
    "        \n",
    "        # reading labels\n",
    "        df = pd.read_csv(path)\n",
    "        self.image_ids = df.image_id.unique()\n",
    "        self.length = len(self.image_ids)\n",
    "        \n",
    "        if self.is_train:\n",
    "            self.labels = df[['grapheme_root','vowel_diacritic','consonant_diacritic']].values\n",
    "        else:\n",
    "            self.labels = [None] * self.length\n",
    "        \n",
    "        # reading images\n",
    "        iterator = [os.path.join(image_path, f'{x}.png') for x in self.image_ids]\n",
    "        with mp.Pool(8) as pool:\n",
    "            iterator = pool.imap(load_image, iterator)\n",
    "            if verbose:\n",
    "                iterator = tqdm(iterator, total=len(self.image_ids))\n",
    "            self.images = list(iterator)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.target == 'reconstruct':\n",
    "            print(self.transform[0])\n",
    "            print(self.transform[1])\n",
    "            print(self.images[idx])\n",
    "            \n",
    "            img = self.images[idx]\n",
    "            img1 = self.transform[0](img)\n",
    "            img2 = self.transform[1](img)\n",
    "            return img1, img2\n",
    "        \n",
    "        return self.transform(self.images[idx]), self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "Autoencoder_Train = BengaliDataset(train_path, image_path, target='reconstruct',\n",
    "    transform=(my_transforms['train'], my_transforms['default']),\n",
    "    is_train=True, verbose=True)\n",
    "Autoencoder_Test = BengaliDataset(test_path, image_path, target='reconstruct',\n",
    "    transform=(my_transforms['test'], my_transforms['default']),\n",
    "    is_train=False, verbose=True)\n",
    "\n",
    "for idx in range(5):\n",
    "    img, target = Autoencoder_Train[idx]\n",
    "    print(target.size(), type(target))\n",
    "    print(img.size(), type(img))\n",
    "    \n",
    "    plt.imshow(TF.to_pil_image(img), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(TF.to_pil_image(target), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
